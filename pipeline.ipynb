{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e28dbd9",
   "metadata": {},
   "source": [
    "# Offline Learning Resources for Comprehensive Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ffc7f",
   "metadata": {},
   "source": [
    "## Load libraries and configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d0186e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Config loaded successfully.\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data.imagenet_loader import ContinualImageNet\n",
    "from models.backbone import get_backbone\n",
    "from strategies.joint_training import JointTrainer\n",
    "from utils.metrics import CLMetrics\n",
    "\n",
    "\n",
    "with open('config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "device = torch.device(cfg['experiment']['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Config loaded successfully.\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d1c15",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6e68b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/imagenet256/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Setup Data & Metrics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cl_data = \u001b[43mContinualImageNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mroot_dir\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_tasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_tasks\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtotal_classes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_workers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m cl_metrics = CLMetrics(cfg[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mnum_tasks\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     11\u001b[39m history = {\u001b[33m'\u001b[39m\u001b[33macc\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mforget\u001b[39m\u001b[33m'\u001b[39m: []}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/e/Development/Python/ContinualLearning/OfflineLearningImageNet/data/imagenet_loader.py:30\u001b[39m, in \u001b[36mContinualImageNet.__init__\u001b[39m\u001b[34m(self, root_dir, num_tasks, total_classes, batch_size, num_workers)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.train_transform = transforms.Compose([\n\u001b[32m     17\u001b[39m     transforms.RandomResizedCrop(\u001b[32m224\u001b[39m),\n\u001b[32m     18\u001b[39m     transforms.RandomHorizontalFlip(),\n\u001b[32m     19\u001b[39m     transforms.ToTensor(),\n\u001b[32m     20\u001b[39m     transforms.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m]),\n\u001b[32m     21\u001b[39m ])\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.val_transform = transforms.Compose([\n\u001b[32m     24\u001b[39m     transforms.Resize(\u001b[32m256\u001b[39m),\n\u001b[32m     25\u001b[39m     transforms.CenterCrop(\u001b[32m224\u001b[39m),\n\u001b[32m     26\u001b[39m     transforms.ToTensor(),\n\u001b[32m     27\u001b[39m     transforms.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m]),\n\u001b[32m     28\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28mself\u001b[39m.full_train_dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m.full_val_dataset = datasets.ImageFolder(os.path.join(root_dir, \u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m), transform=\u001b[38;5;28mself\u001b[39m.val_transform)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Tạo mapping giai đoạn (tasks)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:149\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    140\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     classes, class_to_idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     samples = \u001b[38;5;28mself\u001b[39m.make_dataset(\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.root,\n\u001b[32m    152\u001b[39m         class_to_idx=class_to_idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m         allow_empty=allow_empty,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m.loader = loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:234\u001b[39m, in \u001b[36mDatasetFolder.find_classes\u001b[39m\u001b[34m(self, directory)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03m        directory/\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:41\u001b[39m, in \u001b[36mfind_classes\u001b[39m\u001b[34m(directory)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     classes = \u001b[38;5;28msorted\u001b[39m(entry.name \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry.is_dir())\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m     43\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/imagenet256/train'"
     ]
    }
   ],
   "source": [
    "# Setup Data & Metrics\n",
    "cl_data = ContinualImageNet(\n",
    "    root_dir=cfg['data']['root_dir'],\n",
    "    num_tasks=cfg['data']['num_tasks'],\n",
    "    total_classes=cfg['data']['total_classes'],\n",
    "    batch_size=cfg['training']['batch_size'],\n",
    "    num_workers=cfg['data']['num_workers']\n",
    ")\n",
    "\n",
    "cl_metrics = CLMetrics(cfg['data']['num_tasks'])\n",
    "history = {'acc': [], 'forget': []}\n",
    "\n",
    "model = get_backbone(cfg)\n",
    "trainer = JointTrainer(model, device, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d9377",
   "metadata": {},
   "source": [
    "## Train model with offline learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e4986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tasks = cfg['data']['num_tasks']\n",
    "epochs = cfg['training']['epochs_per_task']\n",
    "save_dir = cfg['experiment']['save_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bde509",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f762bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== PHASE 1/5 ==========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cl_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tasks):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m PHASE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_id+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_tasks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     train_loader = \u001b[43mcl_data\u001b[49m.get_data_loader(task_id, mode=\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m, cumulative=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m     trainer.train(train_loader, epochs=epochs)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluating metrics...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cl_data' is not defined"
     ]
    }
   ],
   "source": [
    "for task_id in range(num_tasks):\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"   PHASE {task_id+1} / {num_tasks}: Learning Task {task_id}\")\n",
    "    print(f\"{'='*30}\")\n",
    "\n",
    "    print(f\"Loading cumulative data (Task 0-{task_id})...\")\n",
    "    train_loader = cl_data.get_data_loader(task_id, mode='train', cumulative=True)\n",
    "    \n",
    "    trainer.train(train_loader, epochs=epochs)\n",
    "    trainer.save_checkpoint(task_id, save_dir)\n",
    "    task_accuracies = []\n",
    "    \n",
    "    for test_task in range(task_id + 1):\n",
    "        val_loader = cl_data.get_data_loader(test_task, mode='val', cumulative=False)\n",
    "        acc = trainer.evaluate(val_loader)\n",
    "        \n",
    "        cl_metrics.update(train_phase=task_id, test_task=test_task, accuracy=acc)\n",
    "        history['task_acc'][test_task].append(acc)\n",
    "        task_accuracies.append(acc)\n",
    "        \n",
    "        print(f\"    [Test Task {test_task}]: {acc:.2f}%\")\n",
    "        \n",
    "    # 3. STATS\n",
    "    avg_acc, avg_forget = cl_metrics.calculate_metrics(task_id)\n",
    "    history['avg_acc'].append(avg_acc)\n",
    "    history['avg_forget'].append(avg_forget)\n",
    "    \n",
    "    print(f\"\\n[Summary phase {task_id}] Avg Acc: {avg_acc:.2f}% | Forget: {avg_forget:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5f2fe",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60db7df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     86\u001b[39m     plt.show()\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m task_cm_norm\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m y_true, y_pred = get_all_predictions(\u001b[43mmodel\u001b[49m, cl_data, device, cfg[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mnum_tasks\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     91\u001b[39m _ = plot_advanced_metrics(history, y_true, y_pred, cfg[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mnum_tasks\u001b[39m\u001b[33m'\u001b[39m], cfg[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtotal_classes\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_all_predictions(model, dataset, device, num_tasks):\n",
    "    \"\"\"\n",
    "    Hàm lấy toàn bộ dự đoán trên tập Validation gộp (tất cả các task).\n",
    "    Trả về: y_true, y_pred\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(\"Collecting predictions from all tasks for analysis...\")\n",
    "    \n",
    "    loader, _ = dataset.get_data_loader(num_tasks - 1, mode='val', cumulative=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in notebook(loader, desc=\"Inference\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(labels.numpy())\n",
    "            \n",
    "    return np.array(all_targets), np.array(all_preds)\n",
    "\n",
    "def plot_advanced_metrics(history, y_true, y_pred, num_tasks, total_classes):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    for t_id, accs in history['task_acc'].items():\n",
    "        if len(accs) > 0:\n",
    "            phases = range(t_id, num_tasks) \n",
    "            current_accs = accs[:len(phases)]\n",
    "            ax1.plot(phases, current_accs, marker='o', linewidth=2, label=f'Task {t_id}')\n",
    "            \n",
    "    ax1.set_title(\"Performance Evolution per Task\", fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel(\"Training Phase (After learning Task X)\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "    ax1.set_xticks(range(num_tasks))\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(total_classes))\n",
    "    classes_per_task = total_classes // num_tasks\n",
    "    task_cm = np.zeros((num_tasks, num_tasks))\n",
    "    \n",
    "    for i in range(num_tasks):\n",
    "        for j in range(num_tasks):\n",
    "            row_start, row_end = i*classes_per_task, (i+1)*classes_per_task\n",
    "            col_start, col_end = j*classes_per_task, (j+1)*classes_per_task\n",
    "            \n",
    "            task_cm[i, j] = np.sum(cm[row_start:row_end, col_start:col_end])\n",
    "\n",
    "\n",
    "    row_sums = task_cm.sum(axis=1, keepdims=True)\n",
    "    task_cm_norm = np.divide(task_cm, row_sums, where=row_sums!=0) * 100\n",
    "    \n",
    "    sns.heatmap(task_cm_norm, annot=True, fmt=\".1f\", cmap=\"OrRd\", ax=ax2, vmin=0, vmax=100)\n",
    "    ax2.set_title(\"Task confusion matrix (Row: True, Col: Pred)\", fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel(\"Predicted task ID\", fontsize=12)\n",
    "    ax2.set_ylabel(\"True task ID\", fontsize=12)\n",
    "\n",
    "    ax3 = plt.subplot(2, 1, 2)\n",
    "    \n",
    "    class_accuracies = []\n",
    "    cm_diag = cm.diagonal()\n",
    "    class_totals = cm.sum(axis=1)\n",
    "    per_class_acc = np.divide(cm_diag, class_totals, where=class_totals!=0) * 100\n",
    "    sns.histplot(per_class_acc, bins=30, kde=True, ax=ax3, color='teal')\n",
    "    ax3.axvline(np.mean(per_class_acc), color='r', linestyle='--', label=f'Mean Acc: {np.mean(per_class_acc):.2f}%')\n",
    "    \n",
    "    ax3.set_title(\"Distribution of per-Class accuracy\", fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel(\"Accuracy (%)\", fontsize=12)\n",
    "    ax3.set_ylabel(\"Number of Classes\", fontsize=12)\n",
    "    ax3.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return task_cm_norm\n",
    "\n",
    "y_true, y_pred = get_all_predictions(model, cl_data, device, cfg['data']['num_tasks'])\n",
    "_ = plot_advanced_metrics(history, y_true, y_pred, cfg['data']['num_tasks'], cfg['data']['total_classes'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
